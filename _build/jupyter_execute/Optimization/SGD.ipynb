{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stochastic Gradient Descent\n",
    "While working with Machine Learning (ML) it is common to have a dataset $(X, Y) = \\{ (x^i, y^i) \\}_{i=1}^N$, and a parametric function $f_\\theta(x)$ whose specific shape depends on the task. As already cited, _training_ a Machine Learning model is basically an optimization problem, where we need to find parameters $\\theta$ (known as *weights*), such that $f_\\theta(x^i) \\approx y^i$ for any $i = 1, \\dots, N$. To do that, we usually consider a **loss function**, which in this case depends on the weights $\\theta$ and the dataset $(X, Y)$. We will indicate is as $\\ell(\\theta; X, Y)$.\n",
    "\n",
    "In most of the cases, $\\ell(\\theta; X, Y)$ can be written as a sum of simpler components, each depending on a specific datapoint, i.e.\n",
    "\n",
    "$$\n",
    "\\ell(\\theta; X, Y) = \\sum_{i=1}^N \\ell_i(\\theta; x^i, y^i)\n",
    "$$\n",
    "\n",
    "and the training optimization problem becomes\n",
    "\n",
    "$$\n",
    "\\theta^* = \\arg\\min_\\theta \\ell(\\theta; X, Y) = \\arg\\min_\\theta  \\sum_{i=1}^N \\ell_i(\\theta; x^i, y^i)\n",
    "$$\n",
    "\n",
    "Which can be solved by Gradient Descent algorithm, as\n",
    "\n",
    "$$\n",
    "\\begin{cases}\n",
    "\t\\theta_0 \\in \\mathbb{R}^d \\\\\n",
    "\t\\theta_{k+1} = \\theta_k - \\alpha_k \\nabla_\\theta \\ell(\\theta_k; X, Y) = \\theta_k - \\alpha_k \\sum_{i=1}^N \\nabla_\\theta \\ell_i(\\theta_k; x^i, y^i)\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "Where we used that $\\nabla_\\theta \\ell(\\theta_k; X, Y) = \\nabla_\\theta \\sum_{i=1}^N \\ell_i(\\theta_k; x^i, y^i) = \\sum_{i=1}^N \\nabla_\\theta \\ell_i(\\theta_k; x^i, y^i)$.\n",
    "\n",
    "Therefore, to compute each iteration of Gradient Descent we need the gradient with respect to the weights of the objective functions, which is done by summing up the gradients of each independent functions $\\ell_i(\\theta; x^i, y^i)$.\n",
    "\n",
    "As an example, a common loss function in Machine Learning is the Mean Squared Error (MSE), defined by\n",
    "\n",
    "$$\n",
    "\\ell(\\theta; X, Y) := MSE(f_\\theta(X), Y) = \\frac{1}{N} \\sum_{i=1}^N (f_\\theta(x^i) - y^i)^2 = \\sum_{i=1}^N  \\underbrace{\\frac{1}{N} (f_\\theta(x^i) - y^i)^2}_{=: \\ell_i(\\theta; x^i, y^i)}.\n",
    "$$\n",
    "\n",
    "Computing $\\nabla_\\theta MSE(f_\\theta(X), Y)$ is not hard, since\n",
    "\n",
    "$$\n",
    "\\nabla_\\theta MSE(f_\\theta(X), Y) = \\nabla_\\theta \\sum_{i=1}^N \\frac{1}{N} (f_\\theta(x^i) - y^i)^2 =\\ \\sum_{i=1}^N \\nabla_\\theta (f_\\theta(x^i) - y^i)^2,\n",
    "$$\n",
    "\n",
    "but:\n",
    "\n",
    "$$\n",
    "\\nabla_\\theta (f_\\theta(x^i) - y^i)^2 = 2 (f_\\theta(x^i) - y^i) \\nabla_\\theta f_\\theta(x^i)\n",
    "$$\n",
    "\n",
    "by applying the chain rule. When $\\nabla_\\theta f_\\theta(x^i)$ can be explicitly computed (it depends on the shape of $f_\\theta$), then the gradient descent iteration to solve the training optimization problem can be implemented as\n",
    "\n",
    "$$\n",
    "\\theta_{k+1} = \\theta_k - \\alpha_k \\underbrace{\\frac{2}{N} \\sum_{i=1}^N (f_\\theta(x^i) - y^i) \\nabla_\\theta f_\\theta(x^i)}_{\\nabla_\\theta \\ell(\\theta; X, Y)}.\n",
    "$$\n",
    "\n",
    "## Stochastic Gradient Descent (SGD) algorithm\n",
    "Unfortunately, even if it is easy to compute the gradient of $\\ell_i(\\theta; x^i, y^i)$ for any $i$, when the number of samples $N$ is large (which is common in Machine Learning), the computation of the full gradient $\\nabla_\\theta \\ell(\\theta; X, Y)$ is prohibitive, mostly because of memory limitations. For this reason, in such optimization problems, instead of using a standard GD algorithm, it is better using the Stochastic Gradient Descent (SGD) method. That is a variant of the classical GD where, instead of computing $\\nabla_\\theta \\ell(\\theta; X, Y) = \\sum_{i=1}^N \\nabla_\\theta \\ell_i(\\theta; x^i, y^i)$, the summation is reduced to a limited number of terms, called *batch*. The idea is the following:\n",
    "\n",
    "* Given a number $N_{batch} \\ll N$ (usually called `batch_size`), randomly extract a subdataset $\\mathcal{M}$ with $\\|\\mathcal{M}\\| = N_{batch}$ from $(X, Y)$. This set will be called a **batch**;\n",
    "\t\n",
    "* Approximate the true gradient as:\n",
    "\n",
    "$$\n",
    "\\nabla_\\theta \\ell(\\theta; X, Y) = \\sum_{i=1}^N \\nabla_\\theta \\ell_i(\\theta; x^i, y^i),\n",
    "$$ \n",
    "\n",
    "where\n",
    "\n",
    "$$\n",
    "\\nabla_\\theta \\ell(\\theta; \\mathcal{M}) = \\sum_{i\\in \\mathcal{M}} \\nabla_\\theta \\ell_i(\\theta; x^i, y^i);\n",
    "$$\n",
    "\t\n",
    "* Compute one single iteration of the GD algorithm \n",
    "\n",
    "$$ \n",
    "\\theta_{k+1} = \\theta_k - \\alpha_k \\nabla_\\theta \\ell(\\theta; \\mathcal{M});\n",
    "$$\n",
    "\n",
    "* Repeat until you have extracted the full dataset. Notice that the random sampling at each iteration is done without replacement.\n",
    "\n",
    "Each iteration of the algorithm above is usually called *batch iteration*. When the whole dataset has been processed, we say that we completed an **epoch** of the SGD method. This algorithm should be repeated for a fixed number $E$ of epochs to reach convergence.\n",
    "\n",
    "Below its a Python implementation of the SGD algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def SGD(loss, grad_loss, D, theta0, alpha, batch_size, n_epochs):\n",
    "    X, y = D  # Unpack the data\n",
    "    N = X.shape[0] # We assume both X and Y has shape (N, )\n",
    "    d = theta0.shape[0] # While theta0 has shape (d, )\n",
    "    idx = np.arange(0, N) # This is required for the shuffling\n",
    "    \n",
    "    # Initialization of history vectors\n",
    "    theta_history = np.zeros((n_epochs, d))  # Save parameters at each epoch\n",
    "    loss_history = np.zeros((n_epochs, ))  # Save loss values at each epoch\n",
    "    grad_norm_history = np.zeros((n_epochs, ))  # Save gradient norms at each epoch\n",
    "    \n",
    "    # Initialize weights\n",
    "    theta = theta0\n",
    "    for epoch in range(n_epochs):\n",
    "        # Shuffle the data at the beginning of each epoch\n",
    "        np.random.shuffle(idx)\n",
    "        X = X[idx]\n",
    "        y = y[idx]\n",
    "\n",
    "        # Initialize a vector that saves the gradient of the loss at each iteration\n",
    "        grad_loss_vec = []\n",
    "\n",
    "        for batch_start in range(0, N, batch_size):\n",
    "            batch_end = min(batch_start + batch_size, N)\n",
    "            X_batch = X[batch_start:batch_end]\n",
    "            y_batch = y[batch_start:batch_end]\n",
    "            \n",
    "            # Compute the gradient of the loss\n",
    "            gradient = grad_loss(theta, X_batch, y_batch)\n",
    "            grad_loss_vec.append(np.linalg.norm(gradient, 2))\n",
    "\n",
    "            # Update weights\n",
    "            theta = theta - alpha * gradient\n",
    "\n",
    "        # Save the updated values\n",
    "        theta_history[epoch] = theta\n",
    "        loss_history[epoch] = loss(theta, X, y)\n",
    "        grad_norm_history[epoch] = np.mean(grad_loss_vec)\n",
    "    \n",
    "    return theta_history, loss_history, grad_norm_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Exercise:** Test the SGD algorithm to train a polynomial regression model on the `poly_regression_large.csv` data. Try different values for the polynomial degree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{warning}\n",
    "SGD has some drawbacks compared to GD. In particular, there is no way to check whether it reached the convergence (since we can't obviously compute the gradient of $\\ell(\\theta; X, Y)$ to check its distance from zero, as it is required for the first Stopping Criteria) and we can't use the backtracking algorithm, for the same reason. As a consequence, the algorithm will stop ONLY after reaching the fixed number of epochs, and we must set a good value for the step size $\\alpha_k$ by hand. Those problems are partially solved by recent algorithms like SGD with Momentum, Adam, AdaGrad, ... whose study is beyond the scope of the course.\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "teaching",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}